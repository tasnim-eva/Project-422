# -*- coding: utf-8 -*-
"""GroupNo_04_21201839_22299431

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18EiHd0ADXReeElMZVsvuDsb5mtAcgeuH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    confusion_matrix, roc_auc_score, roc_curve,
    precision_recall_curve
)
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

# 2. Load dataset
uploaded = files.upload()
df = pd.read_csv('telco_customer_churn.csv')

# 3. Dataset description
n_rows, n_cols = df.shape
print(f"Data points: {n_rows}, Features: {n_cols}")
print("Problem type: Binary classification (Churn=Yes/No)")
print("Feature types:\n", df.dtypes.value_counts())

# 3.1 Imbalanced dataset analysis
plt.figure(figsize=(6,4))
sns.countplot(data=df, x='Churn', palette='Set2')
plt.title('Churn vs No-Churn Distribution')
plt.show()

# 4. Correlation heatmap
num_df = df.copy()
cats = num_df.select_dtypes(include='object').columns.difference(['customerID'])
for col in cats:
    num_df[col] = pd.Categorical(num_df[col]).codes
num_df = num_df.drop('customerID', axis=1)
plt.figure(figsize=(10,8))
sns.heatmap(num_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Feature Correlation Matrix')
plt.show()
# Interpretation: features most correlated to churn include Contract, tenure, MonthlyCharges

# 5. Preprocessing
# 5.1 Handle anomalies in TotalCharges
df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# 5.2 Impute missing TotalCharges by linear interpolation (cause: infer trend)
df['TotalCharges'].interpolate(method='linear', inplace=True)

# 5.3 Encode features
binary_cols = ['Partner','Dependents','PhoneService','PaperlessBilling']
for col in binary_cols:
    df[col] = df[col].map({'Yes':1,'No':0})  # cause: convert to numeric
df['gender'] = df['gender'].map({'Male':1,'Female':0})
onehot_cols = ['MultipleLines','InternetService','OnlineSecurity','OnlineBackup',
               'DeviceProtection','TechSupport','StreamingTV','StreamingMovies',
               'Contract','PaymentMethod']
X = pd.get_dummies(df.drop(['customerID','Churn'], axis=1),
                   columns=onehot_cols, drop_first=True)
y = df['Churn'].map({'Yes':1,'No':0})

# 5.4 Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 6. Train-test split (stratified 70/30)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, stratify=y, random_state=42
)
print(f"Train/Test shapes: {X_train.shape}, {X_test.shape}")

# 7. Model training & evaluation function
def eval_model(model, name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    print(f"{name} â€“ Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}")
    return y_pred, model

models = {
    'LogisticRegression': LogisticRegression(max_iter=500),
    'KNN': KNeighborsClassifier(),
    'DecisionTree': DecisionTreeClassifier(random_state=42),
    'NaiveBayes': GaussianNB(),
    'NeuralNetwork': MLPClassifier(max_iter=300, random_state=42)
}
results = {}
for name, mdl in models.items():
    y_pred, fitted = eval_model(mdl, name)
    results[name] = {'model': fitted, 'y_pred': y_pred}

# Collect accuracy scores
acc_scores = []
for name, res in results.items():
    acc = accuracy_score(y_test, res['y_pred'])
    acc_scores.append({'Model': name, 'Accuracy': acc})

# Create DataFrame for plotting
acc_df = pd.DataFrame(acc_scores)

# Plot accuracy comparison
plt.figure(figsize=(8,5))
sns.barplot(data=acc_df, x='Model', y='Accuracy', palette='Set1')
plt.title('Prediction Accuracy of All Models')
plt.ylabel('Accuracy')
plt.xlabel('Model')
plt.ylim(0,1)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 8. K-Means clustering (unsupervised insight)
kmeans = KMeans(n_clusters=2, random_state=42)
clusters = kmeans.fit_predict(X_scaled)
df['cluster'] = clusters
plt.figure(figsize=(6,4))
sns.countplot(x='cluster', data=df)
plt.title('KMeans Cluster Counts')
plt.show()

# 9. Precision-Recall curves
plt.figure(figsize=(6,5))
for name, res in results.items():
    if hasattr(res['model'], 'predict_proba'):
        y_score = res['model'].predict_proba(X_test)[:,1]
        p, r, _ = precision_recall_curve(y_test, y_score)
        plt.plot(r, p, label=name)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curves')
plt.legend()
plt.show()

# 10. Confusion matrices
for name, res in results.items():
    cm = confusion_matrix(y_test, res['y_pred'])
    plt.figure(figsize=(4,3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{name} Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# 11. ROC curves
plt.figure(figsize=(8,6))
for name, res in results.items():
    model = res['model']
    if hasattr(model, 'predict_proba'):
        y_score = model.predict_proba(X_test)[:,1]
        fpr, tpr, _ = roc_curve(y_test, y_score)
        auc = roc_auc_score(y_test, y_score)
        plt.plot(fpr, tpr, label=f"{name} (AUC={auc:.2f})")

plt.plot([0,1],[0,1],'k--', label='Random Chance')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves - All Models')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 11.2 Identify and highlight best model
accuracies = {name: accuracy_score(y_test, res['y_pred']) for name, res in results.items()}
best = max(accuracies, key=accuracies.get)
print()
print(f"Best model by accuracy: {best} ({accuracies[best]:.3f})")

